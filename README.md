# FairTalkAI Web Application

## Overview

FairTalkAI is a full-stack application built using FastAPI, Next.js, and PostgreSQL. It utilizes NextAuth with JWT for authentication, 2Auth0 for added security, React Query for efficient data fetching and caching, and Tailwind CSS for styling. The application leverages OpenAI's API to integrate advanced AI functionalities.

This project is developed as a final year project to address a critical challenge in the field of AI ethics â€” detecting bias in language models, specifically Large Language Models (LLMs). It serves as a prototype and a proof of concept for a bias detection tool that analyzes text generated by these models.

### Purpose

The primary goal of this application is to provide an accessible, easy-to-use platform for users to identify and understand biases embedded within texts produced by LLMs. By highlighting potential biases in generated texts, the tool aids researchers, developers, and end-users in fostering more ethical AI usage and development.

### Core Features

- **Bias Detection**: Utilizes GPT-4 to analyze and report biases in texts generated by LLMs.
- **Text Generation**: Incorporates GPT-3.5 to generate text samples that can be analyzed for biases, offering users insights into the functioning and output of contemporary AI models.
- **Model Flexibility**: Allows users to experiment with different OpenAI models in the backend to compare and understand how various models handle bias detection and text generation.

### Use Cases

- **Academic Research**: Enables researchers to study AI-generated text for ethical biases, supporting studies in AI ethics.
- **AI Development**: Assists developers in testing and refining AI models to reduce bias in their outputs.
- **Educational Purposes**: Provides an educational tool for students and instructors to explore and discuss AI bias in a controlled environment.

### Experimentation

The application's architecture allows for flexibility in experimenting with different models. Users are encouraged to modify backend configurations in `utils.py` to integrate different OpenAI models and explore their impact on bias detection.

This project, while a prototype, is designed to be widely accessible, enabling a broad range of users to engage with and contribute to the ongoing conversation about ethics in AI.

## Prerequisites

- Python 3.8+
- Node.js 17.x+
- Yarn package manager
- PostgreSQL 12+
- Docker and Docker Compose (for containerization)

## Technology Stack

- **Backend**: FastAPI, Uvicorn, PostgreSQL
- **Frontend**: Next.js, React, Tailwind CSS
- **Auth**: NextAuth, JWT, oAuth2
- **API Spec**: OpenAPI
- **Other**: React Query Provider, Docker

## Environment Setup

First, clone the repository and navigate into the project directory:

```bash
git clone https://github.com/shneb/FairTalkAI
cd fairtalkai-web
```

### Backend

Create a `.env.backend` file in the root directory with the following environment variables:

```
DEBUG=1
SECRET_KEY=<your-secret-key>
OPENAI_API_KEY=<your-openai-api-key>
POSTGRES_USER=<db-user>
POSTGRES_PASSWORD=<db-password>
POSTGRES_SERVER=<db-server>
POSTGRES_PORT=<db-port>
POSTGRES_DB=<db-name>
JWT_SECRET_KEY=<jwt-secret-key>
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=120
```

### Frontend

Create a `.env.frontend` file in the root directory with the following environment variables:

```
API_URL=http://localhost:8080
NEXTAUTH_URL=http://localhost:3000/api/auth
NEXTAUTH_SECRET=<nextauth-secret>
```

## Running Locally

### Backend

To run the backend server locally:

```bash
poetry install
poetry run uvicorn src.fastapi.main:app --port 8080 --workers 1
```

### Frontend

Install dependencies and run the Next.js development server:

```bash
cd frontend
yarn install
yarn dev
```

## Docker Compose

To run the entire stack with Docker Compose:

```bash
docker-compose up --build
```

## API Specification

Generate TypeScript Axios client from the OpenAPI specification:

```bash
yarn generate
```

## Security Headers

Ensure security headers are configured as specified in the Next.js configuration.

## Contributing

Contributions are welcome! Please read the contributing guidelines in `CONTRIBUTING.md` before submitting pull requests.

## License

This project is licensed under the MIT License - see the `LICENSE.md` file for details.

```

This README provides detailed instructions on how to set up and run the application both locally and using Docker, along with configuring environment variables and contributing to the project. Adjust environment variables as necessary to match your project's configuration.
```
